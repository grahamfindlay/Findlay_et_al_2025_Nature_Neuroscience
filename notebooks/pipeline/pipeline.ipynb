{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from findlay2025a import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1: General preprocessing, data extraction and reduction, and scoring signal generation\n",
    "RUN = False\n",
    "if RUN:\n",
    "    pipeline.extract_imec_sync.do_project()\n",
    "    pipeline.generate_probe_sync_table.do_project(\"ap\")\n",
    "    pipeline.generate_probe_sync_table.do_project(\"lf\")\n",
    "    pipeline.preprocess_lfps.do_project()\n",
    "    pipeline.get_emg_from_lfp.do_project()\n",
    "    pipeline.get_scoring_signals.do_project()\n",
    "    pipeline.generate_scoring_bdfs.do_project()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2: Hippocampus and white matter are localized manually.\n",
    "# This is done in the localize_hippocampus_and_white_matter notebook.\n",
    "# Histology is used as well. This part may be revisited and revised later,\n",
    "# if subsequent analysis shows that localization could be improved.\n",
    "# Generally, the first pass is more than sufficient, since nothing downstream\n",
    "# requires or expects it to be perfect. It mostly serves to limit the amount of\n",
    "# data we have to load into memory for subsequent steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 3A: Get current source densities\n",
    "if RUN:\n",
    "    pipeline.estimate_kcsd_params.do_project()\n",
    "    pipeline.compute_full_kcsd.do_project()\n",
    "\n",
    "# Part 3B: Get phase-amplitude comodulograms\n",
    "if RUN:\n",
    "    pipeline.compute_comodulograms.do_project()\n",
    "    pipeline.plot_comodulograms.do_project()\n",
    "\n",
    "# The relative order of steps 3A and 3B is not important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 4: You must sleep score your data now, if you have not already.\n",
    "# https://github.com/TomBugnon/visbrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 5: Aggregate and preprocess sleep scoring and EMG\n",
    "if RUN:\n",
    "    pipeline.consolidate_visbrain_hypnograms.do_project()\n",
    "    pipeline.consolidate_artifact_annotations.do_project()\n",
    "    pipeline.get_statistical_condition_hypnograms.do_project()\n",
    "    pipeline.aggregate_emg.do_project()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 6A: Compute bandpowers and PSDs\n",
    "if RUN:\n",
    "    # White-matter referenced STFTs\n",
    "    pipeline.compute_cx_bandpowers_and_psds.do_project()\n",
    "    pipeline.aggregate_cortical_bandpowers.do_project()\n",
    "    pipeline.compute_hipp_bandpowers_and_psds.do_project()\n",
    "    pipeline.aggregate_hippocampal_bandpowers.do_project()\n",
    "\n",
    "    # Bipolar-referenced filter-Hilbert instantaneous power (\"ipower\")\n",
    "    pipeline.extract_cx_ipower.do_project(\"idelta\")\n",
    "    pipeline.aggregate_cx_ipower.do_project(\"idelta\")\n",
    "\n",
    "# Part 6B: Preliminary subregion localization and drift estimation\n",
    "if RUN:\n",
    "    pipeline.get_kcsd_profile_for_subregion_localization.do_project()\n",
    "    pipeline.get_ripple_power_profile_for_subregion_localization.do_project()\n",
    "    pipeline.estimate_drift_using_ripple_power_profile.do_project()\n",
    "\n",
    "# The relative order of steps 6A and 6B is not important.\n",
    "# 6A does not use or require any drift correction or subregion localization, because\n",
    "# measures are computed for every channel, and any necessary correction/localization\n",
    "# will be done downstream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 7: Refine subregion localization.\n",
    "# This is done in the localize_hippocampal_subregions notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 8A: Compute Slow/Fast Gamma\n",
    "if RUN:\n",
    "    pipeline.compute_sg_fg.do_project()\n",
    "\n",
    "# Part 8B: Ripple detection\n",
    "if RUN:\n",
    "    pipeline.estimate_ripple_thresholds.do_project()\n",
    "    pipeline.detect_ripples.do_project()\n",
    "    pipeline.postprocess_ripples.do_project()\n",
    "\n",
    "# Part 8C: SPW detection\n",
    "if RUN:\n",
    "    pipeline.estimate_spw_thresholds.do_project()\n",
    "    pipeline.detect_spws.do_project()\n",
    "    pipeline.postprocess_spws.do_project()\n",
    "\n",
    "# Part 8D: Dentate spikes\n",
    "if RUN:\n",
    "    # Threshold estimation and detection are done in the detect_dspks notebook!\n",
    "    # Do that now, then...\n",
    "    pipeline.postprocess_dspks.do_project()\n",
    "\n",
    "# Part 8E: Cortical spindles\n",
    "# Detection is done in the detect_spindles notebook!\n",
    "# No postprocessing of spindles is required.\n",
    "\n",
    "# The relative order of steps 8A-E is not important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 9: Compute various properties of the detected events that were not necessary or efficient to compute in the detection step.\n",
    "# For example, coupling between SPWs and ripples.\n",
    "if RUN:\n",
    "    pipeline.extract_snippets.do_project()\n",
    "    pipeline.compute_spw_ripple_coupling.do_project()\n",
    "    pipeline.compute_spw_triggered_ripple_power.do_project()\n",
    "    pipeline.compute_ripple_triggered_spw_amplitude.do_project()\n",
    "    pipeline.compute_ripple_frequency.do_project()\n",
    "    pipeline.add_swr_snippet_summaries.do_project()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 10: Aggregate the events and export\n",
    "if RUN:\n",
    "    pipeline.aggregate_ripples.do_project()\n",
    "    pipeline.aggregate_spws.do_project()\n",
    "    pipeline.aggregate_dspks.do_project()\n",
    "    pipeline.aggregate_cortical_spindles.do_project()\n",
    "    pipeline.aggregate_measures_and_contrasts.do_project()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 11: Run the notebooks in findlay2025a/notebooks/pipeline/units to compute the unit metrics and PETHs\n",
    "# Part 12: Run the notebooks in findlay2025a/notebooks/data_export to prepare the remaining data for statistics/R\n",
    "# Part 13: Run the notebooks in findlay2025a/r/analysis to reproduce some figures and the statistical supplements\n",
    "# Part 14: Run the notebooks in findlay2025a/notebooks/figures to reproduce the remaining figures in the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
