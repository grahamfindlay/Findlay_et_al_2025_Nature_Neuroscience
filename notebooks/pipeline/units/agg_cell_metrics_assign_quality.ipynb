{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gfindlay/projects/ece/gfys_workspace/.venv/lib/python3.13/site-packages/umap/__init__.py:9: ImportWarning: Tensorflow not installed; ParametricUMAP will be unavailable\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import ecephys\n",
    "import findlay2025a as f25a\n",
    "import wisc_ecephys_tools as wet\n",
    "from ecephys import wne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbsh = wet.get_sglx_project(\"seahorse\")\n",
    "experiment = wet.rats.constants.SleepDeprivationExperiments.NOD\n",
    "sortings = f25a.units.get_nod_sortings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "acg_metrics_file = nbsh.get_project_file(\"acg_metrics.pqt\")\n",
    "if acg_metrics_file.exists():\n",
    "    acg_metrics = pd.read_parquet(acg_metrics_file)\n",
    "else:\n",
    "    acg_metrics = []\n",
    "    for subject, probes in sortings:\n",
    "        subject_metrics = pd.read_parquet(\n",
    "            nbsh.get_experiment_subject_file(experiment, subject, \"acg_metrics.pqt\")\n",
    "        )\n",
    "        subject_metrics[\"subject\"] = subject\n",
    "        acg_metrics.append(subject_metrics)\n",
    "    acg_metrics = pd.concat(acg_metrics)\n",
    "    acg_metrics.to_parquet(acg_metrics_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mua_threshold_kwargs = f25a.units.get_threshold_kwargs()[\"mua\"]\n",
    "mps_metrics_file = nbsh.get_project_file(\"mps_metrics.pqt\")\n",
    "if mps_metrics_file.exists():\n",
    "    mps_metrics = pd.read_parquet(mps_metrics_file)\n",
    "else:\n",
    "    mps_metrics = []\n",
    "    for subject, probes in sortings:\n",
    "        mps = f25a.units.load_nod_multiprobe_sorting(subject, **mua_threshold_kwargs)\n",
    "        mps_metrics.append(mps.properties)\n",
    "    mps_metrics = pd.concat(mps_metrics)\n",
    "    mps_metrics[\"acronym\"] = mps_metrics[\"acronym\"].apply(\n",
    "        f25a.units.hippocampus_to_waxholm\n",
    "    )\n",
    "    mps_metrics = f25a.units.add_major_regions(mps_metrics, as_booleans=False)\n",
    "    mps_metrics.to_parquet(mps_metrics_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(\n",
    "    acg_metrics,\n",
    "    mps_metrics,\n",
    "    on=[\"subject\", \"cluster_id\"],\n",
    "    suffixes=(\"_acg\", None),\n",
    "    how=\"left\",\n",
    ")\n",
    "df.to_parquet(nbsh.get_project_file(\"aggregated_cell_metrics.pqt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quality: {'good', 'mua', nan} excludes 0 clusters.\n",
      "firing_rate: (0.5, inf) excludes 0 clusters.\n",
      "0/19936 clusters excluded by jointly applying filters. 19936 remain.\n",
      "quality: {'good', 'mua', nan} excludes 0 clusters.\n",
      "firing_rate: (0.5, inf) excludes 0 clusters.\n",
      "nn_isolation: (0.7, inf) excludes 1180 clusters.\n",
      "amplitude_cutoff: (0.0, 0.499) excludes 9284 clusters.\n",
      "Callable filter select_inviolate excludes 2464 clusters.\n",
      "10532/19936 clusters excluded by jointly applying filters. 9404 remain.\n",
      "quality: {'good', 'mua', nan} excludes 0 clusters.\n",
      "firing_rate: (0.5, inf) excludes 0 clusters.\n",
      "nn_isolation: (0.8, inf) excludes 2476 clusters.\n",
      "amplitude_cutoff: (0.0, 0.499) excludes 9284 clusters.\n",
      "Callable filter select_inviolate excludes 4220 clusters.\n",
      "11704/19936 clusters excluded by jointly applying filters. 8232 remain.\n",
      "quality: {'good', 'mua', nan} excludes 0 clusters.\n",
      "firing_rate: (0.5, inf) excludes 0 clusters.\n",
      "nn_isolation: (0.9, inf) excludes 6812 clusters.\n",
      "amplitude_cutoff: (0.0, 0.3) excludes 10232 clusters.\n",
      "Callable filter select_inviolate excludes 9992 clusters.\n",
      "15576/19936 clusters excluded by jointly applying filters. 4360 remain.\n"
     ]
    }
   ],
   "source": [
    "id_cols = [\"subject\", \"experiment\", \"probe\", \"cluster_id\"]\n",
    "cluster_quality = (\n",
    "    df[id_cols].drop_duplicates(ignore_index=True).assign(max_quality=np.nan)\n",
    ")\n",
    "for strictness in [\"mua\", \"sua_permissive\", \"sua_moderate\", \"sua_conservative\"]:\n",
    "    threshold_kwargs = f25a.units.get_threshold_kwargs()[strictness]\n",
    "    simple_filters, callable_filters = wne.siutils.get_quality_metric_filters(\n",
    "        **threshold_kwargs\n",
    "    )\n",
    "    strict_df = ecephys.units.siutils.refine_clusters(\n",
    "        df, simple_filters, callable_filters, include_nans=True\n",
    "    )\n",
    "    strict_df = strict_df[id_cols].drop_duplicates(ignore_index=True)\n",
    "    for _, row in strict_df.iterrows():\n",
    "        mask = (cluster_quality[id_cols] == row[id_cols]).all(axis=1)\n",
    "        cluster_quality.loc[mask, \"max_quality\"] = strictness\n",
    "cluster_quality.to_parquet(nbsh.get_project_file(\"cluster_quality.pqt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
